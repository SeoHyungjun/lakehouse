# Production Environment - ArgoCD Configuration
# Production-grade deployment with high availability

# ArgoCD subchart - production resources with HA
argo-cd:
  server:
    replicas: 3
    resources:
      requests:
        memory: 512Mi
        cpu: 250m
      limits:
        memory: 1Gi
        cpu: 500m
    
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: argocd-server
            topologyKey: kubernetes.io/hostname
    
    ingress:
      enabled: true
      ingressClassName: nginx
      annotations:
        cert-manager.io/cluster-issuer: letsencrypt-prod
        nginx.ingress.kubernetes.io/ssl-redirect: "true"
        nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
        nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
      hosts:
        - argocd.company.internal
      tls:
        - secretName: argocd-prod-tls
          hosts:
            - argocd.company.internal
  
  repoServer:
    replicas: 3
    resources:
      requests:
        memory: 512Mi
        cpu: 250m
      limits:
        memory: 1Gi
        cpu: 500m
    
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: argocd-repo-server
            topologyKey: kubernetes.io/hostname
  
  controller:
    replicas: 1
    resources:
      requests:
        memory: 2Gi
        cpu: 1000m
      limits:
        memory: 4Gi
        cpu: 2000m
  
  redis:
    enabled: true
    resources:
      requests:
        memory: 256Mi
        cpu: 100m
      limits:
        memory: 512Mi
        cpu: 200m
  
  # Enable SSO for production
  dex:
    enabled: true
    resources:
      requests:
        memory: 128Mi
        cpu: 50m
      limits:
        memory: 256Mi
        cpu: 100m
  
  # Enable notifications for production
  notifications:
    enabled: true
    resources:
      requests:
        memory: 128Mi
        cpu: 50m
      limits:
        memory: 256Mi
        cpu: 100m
  
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      interval: 30s
  
  # Production RBAC configuration
  configs:
    rbac:
      policy.default: role:readonly
      policy.csv: |
        # Admin role
        p, role:admin, applications, *, */*, allow
        p, role:admin, clusters, *, *, allow
        p, role:admin, repositories, *, *, allow
        p, role:admin, projects, *, *, allow
        p, role:admin, accounts, *, *, allow
        p, role:admin, certificates, *, *, allow
        p, role:admin, gpgkeys, *, *, allow
        
        # Developer role
        p, role:developer, applications, get, */*, allow
        p, role:developer, applications, sync, */*, allow
        p, role:developer, repositories, get, */*, allow
        p, role:developer, projects, get, */*, allow
        
        # Viewer role
        p, role:viewer, applications, get, */*, allow
        p, role:viewer, repositories, get, */*, allow
        p, role:viewer, projects, get, */*, allow
        
        # Group mappings (configure based on your SSO)
        g, argocd-admins, role:admin
        g, argocd-developers, role:developer
        g, argocd-viewers, role:viewer

# Application manifests configuration
environment: prod
repoURL: "https://github.com/your-org/lakehouse.git"
targetRevision: main

# All applications enabled for production
# Note: In production, consider manual sync for critical changes
applications:
  minio:
    enabled: true
    syncPolicy:
      prune: false  # Disable auto-prune in production for safety
      selfHeal: true
  
  icebergCatalog:
    enabled: true
    syncPolicy:
      prune: false
      selfHeal: true
  
  trino:
    enabled: true
    syncPolicy:
      prune: false
      selfHeal: true
  
  airflow:
    enabled: true
    syncPolicy:
      prune: false
      selfHeal: true
  
  observability:
    enabled: true
    syncPolicy:
      prune: false
      selfHeal: true
