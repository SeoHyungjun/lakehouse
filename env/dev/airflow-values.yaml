# Development Environment - Airflow Configuration
# Used by ArgoCD Application: platform/argocd/templates/airflow-application.yaml

airflow:
  # Environment variables for all airflow containers
  env:
    - name: AIRFLOW_CONN_AWS_DEFAULT
      valueFrom:
        secretKeyRef:
          name: airflow-connections
          key: AIRFLOW_CONN_AWS_DEFAULT
    - name: AWS_ACCESS_KEY_ID
      valueFrom:
        secretKeyRef:
          name: minio-creds
          key: accessKeyId
    - name: AWS_SECRET_ACCESS_KEY
      valueFrom:
        secretKeyRef:
          name: minio-creds
          key: secretAccessKey

  # Secrets for all airflow containers
  secret:
    - envName: AIRFLOW_CONN_AWS_DEFAULT
      secretName: airflow-connections
      secretKey: AIRFLOW_CONN_AWS_DEFAULT

  # Webserver - minimal resources for development
  # Note: Airflow webserver requires at least 1Gi to avoid OOMKilled
  webserver:
    replicas: 1
    resources:
      requests:
        memory: 512Mi
        cpu: 100m
      limits:
        memory: 1Gi
        cpu: 250m

  # Scheduler - increased resources for Airflow 3.0
  # Note: Airflow 3.0 requires more memory, 2Gi to avoid OOMKilled
  scheduler:
    replicas: 1
    resources:
      requests:
        memory: 1Gi
        cpu: 250m
      limits:
        memory: 2Gi
        cpu: 500m

  # PostgreSQL - minimal resources for development
  postgresql:
    primary:
      persistence:
        enabled: true
        size: 2Gi
      resources:
        requests:
          memory: 256Mi
          cpu: 100m
        limits:
          memory: 512Mi
          cpu: 250m

  # DAGs - minimal persistence with GitSync
  dags:
    mountPath: "/opt/airflow/dags"
    persistence:
      enabled: false
      # size: 1Gi

    # GitSync configuration for DAG deployment
    gitSync:
      enabled: true
      repo: https://github.com/SeoHyungjun/lakehouse-dags.git
      branch: main
      depth: 1
      wait: 60
      maxFailures: 0
      credentialsSecret: git-sync-cred

  # Airflow configuration - development settings
  config:
    core:
      dags_folder: "/opt/airflow/dags/repo/dags"
      parallelism: 8
      max_active_tasks_per_dag: 4
      max_active_runs_per_dag: 4

    webserver:
      expose_config: "True"
      rbac: "False"
      authenticate: "False"
      base_url: "http://airflow-api-server.lakehouse-platform.svc.cluster.local:8080"

    kubernetes:
      delete_worker_pods: "True"
      delete_worker_pods_on_failure: "False"

    elasticsearch:
      enabled: false

    logging:
      logging_level: "DEBUG"
      remote_logging: "True"
      remote_base_log_folder: "s3://lakehouse/airflow-logs/"
      encryption_secret_key: ""

    # S3 connection for remote logging (MinIO)
    celery:
      s3_conn_id: aws_default

  # Triggerer - disabled for development
  triggerer:
    enabled: false
